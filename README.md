# ðŸŽµ Semantic Sonifier â€” Machine Learning Experiments on Audio Semantics

This repository contains **Experiments 5 to 9** based on the *Semantic Sonifier* dataset.  
These experiments explore clustering, dimensionality reduction, sequence modeling, decision trees,  
and ensemble methods to analyze and classify sound semantics such as emotion, tempo, and pitch.

---

## ðŸ“Š Dataset

**Source:** Simulated Semantic Sonifier Dataset (or extracted audio features from emotion recordings)  
**File Used:** `semantic_sonifier.csv`

Contains audio-derived semantic attributes:

- `pitch_mean` â€“ Average pitch (Hz)  
- `tempo_bpm` â€“ Tempo in beats per minute  
- `energy` â€“ Relative loudness/intensity  
- `spectral_centroid` â€“ Frequency brightness  
- `zero_crossing_rate` â€“ Signal sharpness  
- `emotion` â€“ Target class (Happy, Sad, Angry, Calm)

---

## ðŸ§ª Experiments Overview

### **Experiment 5 â€“ Clustering (K-Means, Gaussian Mixture, Hierarchical)**
- **Goal:** Group audio samples based on sound features without using emotion labels.  
- **Algorithms:** `KMeans`, `GaussianMixture`, `AgglomerativeClustering`  
- **Visualization:** 2-D PCA cluster comparison.  
- ðŸ“Ž https://colab.research.google.com/drive/1wl1A5V74_leA1cArg1FkaotJWXxP2A-Z?usp=sharing

---

### **Experiment 6 â€“ Principal Component Analysis (PCA)**
- **Goal:** Reduce dimensionality and visualize the main sound-feature components.  
- **Output:** 2-D PCA scatter plot colored by emotion.  
- ðŸ“Žhttps://colab.research.google.com/drive/1wl1A5V74_leA1cArg1FkaotJWXxP2A-Z?usp=sharing

---

### **Experiment 7 â€“ Hidden Markov Model (HMM)**
- **Goal:** Model temporal sound transitions using pitch and energy features.  
- **Tool:** `hmmlearn GaussianHMM` with 4 hidden states.  
- **Output:** Hidden-state predictions and generated semantic-sound samples.  
- ðŸ“Ž https://colab.research.google.com/drive/1wl1A5V74_leA1cArg1FkaotJWXxP2A-Z?usp=sharing

---

### **Experiment 8 â€“ CART (Decision Tree Classification)**
- **Goal:** Predict emotion labels using a decision-tree classifier.  
- **Output:** Tree visualization and model accuracy score.  
- ðŸ“Ž https://colab.research.google.com/drive/1wl1A5V74_leA1cArg1FkaotJWXxP2A-Z?usp=sharing

---

### **Experiment 9 â€“ Ensemble Learning (Random Forest & AdaBoost)**
- **Goal:** Improve semantic-emotion classification through ensemble methods.  
- **Metrics:** Accuracy, Precision, Recall, F1-score.  
- ðŸ“Ž https://colab.research.google.com/drive/1wl1A5V74_leA1cArg1FkaotJWXxP2A-Z?usp=sharing

---

## ðŸ§° Tools & Libraries Used
- **Python 3.10+**  
- **Google Colab**  
- **Libraries:** `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`, `hmmlearn`

---

## ðŸ“ˆ Expected Outcomes
- Discovering natural clusters of sound semantics.  
- Visualization of feature variance using PCA.  
- Temporal modeling of sound transitions via HMM.  
- Accurate and interpretable emotion classification using CART.  
- Improved generalization through Random Forest and AdaBoost.


---

## ðŸ”— Reference
Semantic Sonifier Dataset Â© 2025 (academic simulation or emotion audio features)
